breaks = c("1", "2"),
labels = c("Before", "After"),
limits = factor(c(1, 2))
)  +
labs(y = "Accuracy Change")
df_inc$rt_change <- df_inc$Post_corr_RT - df_inc$Pre_corr_RT
test_rt_TS <- df_inc$rt_change[df_inc$Cond == 'TS']
test_rt_ET <- df_inc$rt_change[df_inc$Cond == 'ET']
test_rt_test <- wilcox.test(test_rt_TS, test_rt_ET)
test_rt_test
test_rt_test$p.value*2
ggplot(df_inc) +
geom_segment(aes(x = 1, xend = 2, y = Pre_corr_RT, yend = Post_corr_RT, col = Cond)) +
theme_bw() +
scale_x_discrete(
breaks = c("1", "2"),
labels = c("Before", "After"),
limits = factor(c(1, 2))
)  +
labs(y = "RT Change")
df <- read.csv('all_subjects.csv')
setwd("I:/SCIENCE-NEXS-neurolab/PROJECTS/PLAYMORE/EEG_project1/Analyses")
library(tidyverse)
library(knitr)
library(yarrr)
#read all data
df <- read.csv('all_subjects.csv')
#select those who meet inclusion critera
df_inc <- filter(df, Included_an1 == 1)
`Pre Test Accuracy` <- c(mean(df_inc$Pre_acc[df_inc$Cond == 'TS']), mean(df_inc$Pre_acc[df_inc$Cond == 'ET']))
`Post Test Accuracy` <- c(mean(df_inc$Post_acc[df_inc$Cond == 'TS']), mean(df_inc$Post_acc[df_inc$Cond == 'ET'], na.rm = TRUE))
`Accuracy Improvement` <- c(sum(mean(df_inc$Post_acc[df_inc$Cond == 'TS'])-mean(df_inc$Pre_acc[df_inc$Cond == 'TS'])), sum(mean(df_inc$Post_acc[df_inc$Cond == 'ET'], na.rm = TRUE)-mean(df_inc$Pre_acc[df_inc$Cond == 'ET'])))
`Pre Test RT` <- c(mean(df_inc$Pre_corr_RT[df_inc$Cond == 'TS']), mean(df_inc$Pre_corr_RT[df_inc$Cond == 'ET']))
`Post Test RT` <-  c(mean(df_inc$Post_corr_RT[df_inc$Cond == 'TS']), mean(df_inc$Post_corr_RT[df_inc$Cond == 'ET'], na.rm = TRUE))
`RT Improvement` <- c(sum(mean(df_inc$Post_corr_RT[df_inc$Cond == 'TS']) - mean(df_inc$Pre_corr_RT[df_inc$Cond == 'TS'])), sum(mean(df_inc$Post_corr_RT[df_inc$Cond == 'ET'], na.rm = TRUE) - mean(df_inc$Pre_corr_RT[df_inc$Cond == 'ET'])))
test <- as.data.frame(rbind(`Pre Test Accuracy`,`Post Test Accuracy`,`Accuracy Improvement`,`Pre Test RT`,`Post Test RT`,`RT Improvement`))
colnames(test) <- c('Touch Screen', 'Eye Tracker')
kable(test, digits = 2)
df_inc$acc_change <- df_inc$Post_acc - df_inc$Pre_acc
test_acc_TS <- df_inc$acc_change[df_inc$Cond == 'TS']
test_acc_ET <- df_inc$acc_change[df_inc$Cond == 'ET']
test_acc_test <- wilcox.test(test_acc_TS, test_acc_ET)
test_acc_test
ggplot(df_inc) +
geom_segment(aes(x = 1, xend = 2, y = Pre_acc, yend = Post_acc, col = Cond)) +
theme_bw() +
scale_x_discrete(
breaks = c("1", "2"),
labels = c("Before", "After"),
limits = factor(c(1, 2))
)  +
labs(y = "Accuracy Change")
df_inc$rt_change <- df_inc$Post_corr_RT - df_inc$Pre_corr_RT
test_rt_TS <- df_inc$rt_change[df_inc$Cond == 'TS']
test_rt_ET <- df_inc$rt_change[df_inc$Cond == 'ET']
test_rt_test <- wilcox.test(test_rt_TS, test_rt_ET)
test_rt_test
df_inc$rt_change <- df_inc$Post_corr_RT - df_inc$Pre_corr_RT
test_rt_TS <- df_inc$rt_change[df_inc$Cond == 'TS']
test_rt_ET <- df_inc$rt_change[df_inc$Cond == 'ET']
test_rt_test <- wilcox.test(test_rt_TS, test_rt_ET)
test_rt_test
test_rt_test$p.value*2
ggplot(df_inc) +
geom_segment(aes(x = 1, xend = 2, y = Pre_corr_RT, yend = Post_corr_RT, col = Cond)) +
theme_bw() +
scale_x_discrete(
breaks = c("1", "2"),
labels = c("Before", "After"),
limits = factor(c(1, 2))
)  +
labs(y = "RT Change")
cor(df_inc$School_year, df_inc$Train_acc, method = c("pearson"))
cor.test(df_inc$School_year, df_inc$Train_acc, method = c("pearson"))
cor.test(df_inc$School_year, df_inc$acc_change, method = c("pearson"))
# Reaction Time
cor.test(df_inc$School_year, df_inc$Train_corr_RT, method = c("pearson"))
cor.test(df_inc$School_year, df_inc$rt_change, method = c("pearson"))
df_inc$sex_dum[df_inc$Sex == "M"] <- 1
View(df_inc)
df_inc$sex_dum[df_inc$Sex == "F"] <- 0
cor.test(df_inc$sex_dum, df_inc$Train_acc, method = c("pearson"))
cor.test(df_inc$sex_dum, df_inc$acc_change, method = c("pearson"))
# Reaction Time & Sex
cor.test(df_inc$sex_dum, df_inc$Train_corr_RT, method = c("pearson"))
cor.test(df_inc$sex_dum, df_inc$rt_change, method = c("pearson"))
# Accuracy & Age
int_acc_age_cor <- cor.test(df_inc$School_year, df_inc$Train_acc, method = c("pearson"))
int_acc_age_cor
int_acc_age_cor$statistic
int_acc_age_cor$parameter
int_acc_age_cor$estimate
int_acc_age_cor$p.value
c(int_acc_age_cor$estimate, int_acc_age_cor$p.value)
test_acc_age_cor <- cor.test(df_inc$School_year, df_inc$acc_change, method = c("pearson"))
int_acc_sex_cor <- cor.test(df_inc$sex_dum, df_inc$Train_acc, method = c("pearson"))
test_acc_sex_cor <- cor.test(df_inc$sex_dum, df_inc$acc_change, method = c("pearson"))
# Reaction Time & Age
int_rt_age_cor <- cor.test(df_inc$School_year, df_inc$Train_corr_RT, method = c("pearson"))
test_rt_age_cor <- cor.test(df_inc$School_year, df_inc$rt_change, method = c("pearson"))
# Reaction Time & Sex
int_rt_sex_cor <- cor.test(df_inc$sex_dum, df_inc$Train_corr_RT, method = c("pearson"))
test_rt_sex_cor <- cor.test(df_inc$sex_dum, df_inc$rt_change, method = c("pearson"))
`Intervention Accuracy & Age` <- c(int_acc_age_cor$estimate, int_acc_age_cor$p.value)
`Intervention Accuracy & Sex` <- c(int_acc_sex_cor$estimate, int_acc_sex_cor$p.value)
`Intervention RT & Age` <- c(int_rt_age_cor$estimate, int_rt_age_cor$p.value)
`Intervention RT & Sex` <- c(int_rt_sex_cor$estimate, int_rt_sex_cor$p.value)
`Pre-Post Accuracy & Age` <- c(test_acc_age_cor$estimate, test_acc_age_cor$p.value)
`Pre-Post Accuracy & Sex` <- c(test_acc_sex_cor$estimate, test_acc_sex_cor$p.value)
`Pre-Post RT & Age` <- c(test_rt_age_cor$estimate, test_rt_age_cor$p.value)
`Pre-Post RT & Sex` <- c(test_rt_sex_cor$estimate, test_rt_sex_cor$p.value)
confounds <- as.data.frame(rbind(c(`Intervention Accuracy & Age`, `Intervention Accuracy & Sex`, `Intervention RT & Age`, `Intervention RT & Sex`, `Pre-Post Accuracy & Age`, `Pre-Post Accuracy & Sex`, `Pre-Post RT & Age`, `Pre-Post RT & Sex`)))
kable(confounds)
View(confounds)
confounds <- as.data.frame(cbind(c(`Intervention Accuracy & Age`, `Intervention Accuracy & Sex`, `Intervention RT & Age`, `Intervention RT & Sex`, `Pre-Post Accuracy & Age`, `Pre-Post Accuracy & Sex`, `Pre-Post RT & Age`, `Pre-Post RT & Sex`)))
View(confounds)
`Intervention Accuracy & Age`
`Intervention Accuracy & Age`
`Intervention Accuracy & Sex`
`Intervention RT & Age`
`Intervention RT & Sex`
`Pre-Post Accuracy & Age`
`Pre-Post Accuracy & Sex`
`Pre-Post RT & Age`
`Pre-Post RT & Sex`
int(test_rt_age_cor$estimate)
integer(test_rt_age_cor$estimate)
class(test_rt_age_cor$estimate)
numeric(test_rt_age_cor$estimate)
value(test_rt_age_cor$estimate)
sum(test_rt_age_cor$estimate)
`Intervention Accuracy & Age` <- c(sum(int_acc_age_cor$estimate), int_acc_age_cor$p.value)
`Intervention Accuracy & Sex` <- c(sum(int_acc_sex_cor$estimate), int_acc_sex_cor$p.value)
`Intervention RT & Age` <- c(sum(int_rt_age_cor$estimate), int_rt_age_cor$p.value)
`Intervention RT & Sex` <- c(sum(int_rt_sex_cor$estimate), int_rt_sex_cor$p.value)
`Pre-Post Accuracy & Age` <- c(sum(test_acc_age_cor$estimate), test_acc_age_cor$p.value)
`Pre-Post Accuracy & Sex` <- c(sum(test_acc_sex_cor$estimate), test_acc_sex_cor$p.value)
`Pre-Post RT & Age` <- c(sum(test_rt_age_cor$estimate), test_rt_age_cor$p.value)
`Pre-Post RT & Sex` <- c(sum(test_rt_sex_cor$estimate), test_rt_sex_cor$p.value)
`Intervention Accuracy & Age`
confounds <- as.data.frame(rbind(c(`Intervention Accuracy & Age`, `Intervention Accuracy & Sex`, `Intervention RT & Age`, `Intervention RT & Sex`, `Pre-Post Accuracy & Age`, `Pre-Post Accuracy & Sex`, `Pre-Post RT & Age`, `Pre-Post RT & Sex`)))
confounds <- as.data.frame(rbind(`Intervention Accuracy & Age`, `Intervention Accuracy & Sex`, `Intervention RT & Age`, `Intervention RT & Sex`, `Pre-Post Accuracy & Age`, `Pre-Post Accuracy & Sex`, `Pre-Post RT & Age`, `Pre-Post RT & Sex`))
kable(confounds)
kable(confounds, digits = 3)
colnames(confounds) <- c('Correlation', 'p-value')
kable(confounds, digits = 3)
confounds$sig[confounds$`p-value` < 0.05] <- `*`
kable(confounds, digits = 3)
class)confounds$`p-value`
class(confounds$`p-value`)
confounds$`p-value` < 0.05
confounds$sig[confounds$`p-value` < 0.05] <- `*`
confounds$sig
View(confounds)
confounds$sig[confounds$`p-value` < 0.05] <- 1
kable(confounds, digits = 3)
confounds$sig[confounds$`p-value` < 0.05] <- '*'
colnames(confounds) <- c('Correlation', 'p-value')
kable(confounds, digits = 3)
confounds$sig[confounds$sig != '*'] <- ''
confounds$sigconfounds$`p-value` > 0.05 <- ''
confounds$sigconfounds$`p-value` > 0.05 <- ' '
confounds$sig[confounds$`p-value` > 0.05] <- ' '
confounds$sig[confounds$`p-value` < 0.05] <- '*'
rm(confounds)
confounds <- as.data.frame(rbind(`Intervention Accuracy & Age`, `Intervention Accuracy & Sex`, `Intervention RT & Age`, `Intervention RT & Sex`, `Pre-Post Accuracy & Age`, `Pre-Post Accuracy & Sex`, `Pre-Post RT & Age`, `Pre-Post RT & Sex`))
confounds$sig[confounds$`p-value` < 0.05] <- '*'
colnames(confounds) <- c('Correlation', 'p-value')
confounds$sig[confounds$`p-value` < 0.05] <- '*'
confounds$sig[confounds$`p-value` > 0.05] <- ' '
kable(confounds, digits = 3)
colnames(confounds) <- c('Correlation', 'p-value', '')
kable(confounds, digits = 3)
# Reaction Time & Age
int_rt_age_cor <- cor.test(df_inc_RT$School_year, df_inc_RT$Train_corr_RT, method = c("pearson"))
test_rt_age_cor <- cor.test(df_inc_RT$School_year, df_inc_RT$rt_change, method = c("pearson"))
View(df_inc_RT)
# Reaction Time & Age
int_rt_age_cor <- cor.test(df_inc_RT$School_year, df_inc_RT$Train_corr_RT, method = c("pearson"))
test_rt_age_cor <- cor.test(df_inc_RT$School_year, df_inc_RT$rt_change, method = c("pearson"))
df_inc_RT$School_year
df_inc_RT$rt_change
# Reaction Time & Sex
int_rt_sex_cor <- cor.test(df_inc$sex_dum[df_inc$Train_eprime_rt_reliability == 1], df_inc$Train_corr_RT[df_inc$Train_eprime_rt_reliability == 1], method = c("pearson"))
# Reaction Time & Age
int_rt_age_cor <- cor.test(df_inc$School_year[df_inc$Train_eprime_rt_reliability == 1], df_inc$Train_corr_RT[df_inc$Train_eprime_rt_reliability == 1], method = c("pearson"))
confounds <- as.data.frame(rbind(`Intervention Accuracy & Age`, `Intervention Accuracy & Sex`, `Intervention RT & Age`, `Intervention RT & Sex`, `Pre-Post Accuracy & Age`, `Pre-Post Accuracy & Sex`, `Pre-Post RT & Age`, `Pre-Post RT & Sex`))
colnames(confounds) <- c('Correlation', 'p-value')
confounds$sig[confounds$`p-value` < 0.05] <- '*'
confounds$sig[confounds$`p-value` > 0.05] <- ' '
colnames(confounds) <- c('Correlation', 'p-value', '')
kable(confounds, digits = 3)
# Reaction Time & Age
#two participants were removed from RT analyses in interventions
int_RT <- df_inc$Train_corr_RT[df_inc$Train_eprime_rt_reliability == 1]
int_RT_age <- df_inc$School_year[df_inc$Train_eprime_rt_reliability == 1]
int_RT_sex <- df_inc$Sex[df_inc$Train_eprime_rt_reliability == 1]
int_RT_sex <- df_inc$sex_dum[df_inc$Train_eprime_rt_reliability == 1]
int_rt_age_cor <- cor.test(int_RT_age, int_RT, method = c("pearson"))
int_rt_age_cor
# Reaction Time & Sex
int_rt_sex_cor <- cor.test(int_RT_sex, int_RT, method = c("pearson"))
int_rt_sex_cor
# Accuracy & Age
int_acc_age_cor <- cor.test(df_inc$School_year, df_inc$Train_acc, method = c("pearson"))
test_acc_age_cor <- cor.test(df_inc$School_year, df_inc$acc_change, method = c("pearson"))
# Accuracy & Gender
df_inc$sex_dum[df_inc$Sex == "M"] <- 1
df_inc$sex_dum[df_inc$Sex == "F"] <- 0
int_acc_sex_cor <- cor.test(df_inc$sex_dum, df_inc$Train_acc, method = c("pearson"))
test_acc_sex_cor <- cor.test(df_inc$sex_dum, df_inc$acc_change, method = c("pearson"))
# Reaction Time & Age
#two participants were removed from RT analyses in interventions
int_RT <- df_inc$Train_corr_RT[df_inc$Train_eprime_rt_reliability == 1]
int_RT_age <- df_inc$School_year[df_inc$Train_eprime_rt_reliability == 1]
int_RT_sex <- df_inc$sex_dum[df_inc$Train_eprime_rt_reliability == 1]
int_rt_age_cor <- cor.test(int_RT_age, int_RT, method = c("pearson"))
test_rt_age_cor <- cor.test(df_inc$School_year, df_inc$rt_change, method = c("pearson"))
# Reaction Time & Sex
int_rt_sex_cor <- cor.test(int_RT_sex, int_RT, method = c("pearson"))
test_rt_sex_cor <- cor.test(df_inc$sex_dum, df_inc$rt_change, method = c("pearson"))
`Intervention Accuracy & Age` <- c(sum(int_acc_age_cor$estimate), int_acc_age_cor$p.value)
`Intervention Accuracy & Sex` <- c(sum(int_acc_sex_cor$estimate), int_acc_sex_cor$p.value)
`Intervention RT & Age` <- c(sum(int_rt_age_cor$estimate), int_rt_age_cor$p.value)
`Intervention RT & Sex` <- c(sum(int_rt_sex_cor$estimate), int_rt_sex_cor$p.value)
`Pre-Post Accuracy & Age` <- c(sum(test_acc_age_cor$estimate), test_acc_age_cor$p.value)
`Pre-Post Accuracy & Sex` <- c(sum(test_acc_sex_cor$estimate), test_acc_sex_cor$p.value)
`Pre-Post RT & Age` <- c(sum(test_rt_age_cor$estimate), test_rt_age_cor$p.value)
`Pre-Post RT & Sex` <- c(sum(test_rt_sex_cor$estimate), test_rt_sex_cor$p.value)
confounds <- as.data.frame(rbind(`Intervention Accuracy & Age`, `Intervention Accuracy & Sex`, `Intervention RT & Age`, `Intervention RT & Sex`, `Pre-Post Accuracy & Age`, `Pre-Post Accuracy & Sex`, `Pre-Post RT & Age`, `Pre-Post RT & Sex`))
colnames(confounds) <- c('Correlation', 'p-value')
confounds$sig[confounds$`p-value` < 0.05] <- '*'
confounds$sig[confounds$`p-value` > 0.05] <- ' '
colnames(confounds) <- c('Correlation', 'p-value', '')
kable(confounds, digits = 3)
max(int_RT)
min(int_RT)
int_RT_sexL[int_RT_sex = 1] <- "M"
int_RT_sexL <- 1:length(int_RT_sex)
int_RT_sexL[int_RT_sex = 1] <- "M"
int_RT_sexL
int_RT_sex
int_RT_sexL <- df_inc$Sex[df_inc$Train_eprime_rt_reliability == 1]
int_RT_sexL
pirateplot(formula = int_RT~int_RT_sexL, #which variables are you using
data = df_inc_RT,
theme = 0, #check out different themes in the guide page linked at the top, theme 0 is starting from scratch
main = "Intervention RT", #title of the graph
par(cex.main = 1.2), #set the size of your title
xlab="Intervention Group", #label of the x axis
ylab="DT ms", #label of the y axis
cex.lab = 1.2, #size of the axis labels
pal = "basel", # color palette, look at the instruction link to identify different palettes
inf.method = 'hdi', # method of inference - either High Density Interval (hdi, from Bayesian stats), or standard Confidence Interval (ci)
bean.f.o = 0.5, # Bean fill darkness
point.o = .3, # points darkness
inf.f.o = .5, # Inference fill
inf.b.o = .5, # Inference border
avg.line.o = 0.7, # Average line darkness
inf.f.col = "white", # Inf fill col
inf.b.col = "black", # Inf border col
avg.line.col = "black", # avg line col
point.pch = 20, #point shape
point.col = "black", #point colour
point.cex = 1, #point size
gl.col = "#FFCCFF", #gridlines and colour
yaxt ="n", # remove the automatic scale on the axis Y
quant = c(.05, .95) #set the quantile, here within 5% on each side to indicate outliers
)
axis(2, at = seq(1600, 3500, by = 400)) #set the numbers on the y axis
int_RT_sexL <- df_inc$Sex[df_inc$Train_eprime_rt_reliability == 1]
int_RT_years <- df_inc$Age[df_inc$Train_eprime_rt_reliability == 1]
max(int_RT_years)
min(int_RT_years)
pirateplot(formula = int_RT_years~int_RT_sexL, #which variables are you using
data = df_inc_RT,
theme = 0, #check out different themes in the guide page linked at the top, theme 0 is starting from scratch
main = "Intervention RT", #title of the graph
par(cex.main = 1.2), #set the size of your title
xlab="Intervention Group", #label of the x axis
ylab="DT ms", #label of the y axis
cex.lab = 1.2, #size of the axis labels
pal = "basel", # color palette, look at the instruction link to identify different palettes
inf.method = 'hdi', # method of inference - either High Density Interval (hdi, from Bayesian stats), or standard Confidence Interval (ci)
bean.f.o = 0.5, # Bean fill darkness
point.o = .3, # points darkness
inf.f.o = .5, # Inference fill
inf.b.o = .5, # Inference border
avg.line.o = 0.7, # Average line darkness
inf.f.col = "white", # Inf fill col
inf.b.col = "black", # Inf border col
avg.line.col = "black", # avg line col
point.pch = 20, #point shape
point.col = "black", #point colour
point.cex = 1, #point size
gl.col = "#FFCCFF", #gridlines and colour
yaxt ="n", # remove the automatic scale on the axis Y
quant = c(.05, .95) #set the quantile, here within 5% on each side to indicate outliers
)
axis(2, at = seq(6, 8, by = 1)) #set the numbers on the y axis
knitr::opts_chunk$set(echo = FALSE, eval = TRUE, warning = FALSE, message = FALSE)
Sys.setenv(LANG = "en")
library(knitr)
library(tidyverse)
library(yarrr)
setwd("I:/SCIENCE-NEXS-neurolab/PROJECTS/PLAYMORE/Boost/TVA/data/model_outputs")
df <- read.csv("all_TVA_edited.csv")
#sort the data by ID
df <- df[order(df$ID),]
#get rid of participant doesn't match with the boost data
df <- filter(df, ID != 11202)
#import the data from school
setwd("I:/SCIENCE-NEXS-neurolab/PROJECTS/PLAYMORE/Boost")
df_school <- read.csv("boostdata.csv")
#extract teacher ranks
df_teacher <- drop_na(df_school, teacherrank)
df_teacher <- select(df_teacher, ID, teacherrank, laesesubgruppe)
#add to the main dataframe
df <- left_join(df, df_teacher, by = "ID")
#re-arrange the school data
df_school <- select(df_school, ID, time, laesudenkor)
df_school <- spread(df_school, time, laesudenkor)
#add to the main dataframe
df <- left_join(df, df_school, by = "ID")
df <- select(df, -`<NA>`)
#calculate improvement in reading
df$improvement <- df$`2` - df$`1`
missing_pre <- 1
missing_post <- 1
for (i in 1:length(df$ID)){
if(is.na(df$C_pre[i])){
missing_pre <- append(missing_pre, df$ID[i], length(missing_pre))
}
}
missing_pre <- missing_pre[-1]
for (i in 1:length(df$ID)){
if(is.na(df$C_post[i])){
missing_post <- append(missing_post, df$ID[i], length(missing_post))
}
}
missing_post <- missing_post[-1]
missing_pre[(length(missing_pre)+1):length(missing_post)] <- ""
df_missing <- data.frame(cbind(missing_pre, missing_post))
kable(df_missing)
df_fulldata <- drop_na(df, C_pre)
df_fulldata <- drop_na(df_fulldata, C_post)
#int pre, int post, int delta, cont pre, cont post, cont delta
#K <- c(mean(df_fulldata$K_pre[df_fulldata$cond == "grov"]), mean(df_fulldata$K_post[df_fulldata$cond == "grov"]), (mean(df_fulldata$K_post[df_fulldata$cond == "grov"]) - mean(df_fulldata$K_pre[df_fulldata$cond == "grov"])), mean(df_fulldata$K_pre[df_fulldata$cond == "kon"]), mean(df_fulldata$K_post[df_fulldata$cond == "kon"]), (mean(df_fulldata$K_post[df_fulldata$cond == "kon"]) - mean(df_fulldata$K_pre[df_fulldata$cond == "kon"])))
#error_rate <- c(mean(df_fulldata$error_pre[df_fulldata$cond == "grov"]), mean(df_fulldata$error_post[df_fulldata$cond == "grov"]), (mean(df_fulldata$error_post[df_fulldata$cond == "grov"]) - mean(df_fulldata$error_pre[df_fulldata$cond == "grov"])), mean(df_fulldata$error_pre[df_fulldata$cond == "kon"]), mean(df_fulldata$error_post[df_fulldata$cond == "kon"]), (mean(df_fulldata$error_post[df_fulldata$cond == "kon"]) - mean(df_fulldata$error_pre[df_fulldata$cond == "kon"])))
#df_desc <- data.frame(rbind(K, error_rate))
#colnames(df_desc) <- c("Int Pre", "Int Post", "Int Delta", "Con Pre", "Cont Post", "Cont Delta")
#kable(df_desc)
#Remove one outlier that has more thab 4 on K post intervention
df_fulldata <- filter(df_fulldata, K_post < 4)
#mark improvement groups
df_fulldata$improvgroup[df_fulldata$improvement < 1] <- "low"
df_fulldata$improvgroup[df_fulldata$improvement > 0] <- "high"
Int_LowRank <- c(sum(df_fulldata$cond == "grov" & df_fulldata$laesesubgruppe == "low", na.rm=TRUE), mean(df_fulldata$K_pre[df_fulldata$cond == "grov" & df_fulldata$laesesubgruppe == "low"], na.rm=TRUE), mean(df_fulldata$K_post[df_fulldata$cond == "grov" & df_fulldata$laesesubgruppe == "low"], na.rm=TRUE), mean(df_fulldata$error_pre[df_fulldata$cond == "grov" & df_fulldata$laesesubgruppe == "low"], na.rm=TRUE), mean(df_fulldata$error_post[df_fulldata$cond == "grov" & df_fulldata$laesesubgruppe == "low"], na.rm=TRUE))
Int_HighRank <- c(sum(df_fulldata$cond == "grov" & df_fulldata$laesesubgruppe == "high", na.rm=TRUE), mean(df_fulldata$K_pre[df_fulldata$cond == "grov" & df_fulldata$laesesubgruppe == "high"], na.rm=TRUE), mean(df_fulldata$K_post[df_fulldata$cond == "grov" & df_fulldata$laesesubgruppe == "high"], na.rm=TRUE), mean(df_fulldata$error_pre[df_fulldata$cond == "grov" & df_fulldata$laesesubgruppe == "high"], na.rm=TRUE), mean(df_fulldata$error_post[df_fulldata$cond == "grov" & df_fulldata$laesesubgruppe == "high"], na.rm=TRUE))
Con_LowRank <- c(sum(df_fulldata$cond == "kon" & df_fulldata$laesesubgruppe == "low", na.rm=TRUE), mean(df_fulldata$K_pre[df_fulldata$cond == "kon" & df_fulldata$laesesubgruppe == "low"], na.rm=TRUE), mean(df_fulldata$K_post[df_fulldata$cond == "kon" & df_fulldata$laesesubgruppe == "low"], na.rm=TRUE), mean(df_fulldata$error_pre[df_fulldata$cond == "kon" & df_fulldata$laesesubgruppe == "low"], na.rm=TRUE), mean(df_fulldata$error_post[df_fulldata$cond == "kon" & df_fulldata$laesesubgruppe == "low"], na.rm=TRUE))
Con_HighRank <- c(sum(df_fulldata$cond == "kon" & df_fulldata$laesesubgruppe == "high", na.rm=TRUE), mean(df_fulldata$K_pre[df_fulldata$cond == "kon" & df_fulldata$laesesubgruppe == "high"], na.rm=TRUE), mean(df_fulldata$K_post[df_fulldata$cond == "kon" & df_fulldata$laesesubgruppe == "high"], na.rm=TRUE), mean(df_fulldata$error_pre[df_fulldata$cond == "kon" & df_fulldata$laesesubgruppe == "high"], na.rm=TRUE), mean(df_fulldata$error_post[df_fulldata$cond == "kon" & df_fulldata$laesesubgruppe == "high"], na.rm=TRUE))
Int_LowImp <- c(sum(df_fulldata$cond == "grov" & df_fulldata$improvgroup == "low", na.rm=TRUE), mean(df_fulldata$K_pre[df_fulldata$cond == "grov" & df_fulldata$improvgroup == "low"], na.rm=TRUE), mean(df_fulldata$K_post[df_fulldata$cond == "grov" & df_fulldata$improvgroup == "low"], na.rm=TRUE), mean(df_fulldata$error_pre[df_fulldata$cond == "grov" & df_fulldata$improvgroup == "low"], na.rm=TRUE), mean(df_fulldata$error_post[df_fulldata$cond == "grov" & df_fulldata$improvgroup == "low"], na.rm=TRUE))
Int_HighImp <- c(sum(df_fulldata$cond == "grov" & df_fulldata$improvgroup == "high", na.rm=TRUE), mean(df_fulldata$K_pre[df_fulldata$cond == "grov" & df_fulldata$improvgroup == "high"], na.rm=TRUE), mean(df_fulldata$K_post[df_fulldata$cond == "grov" & df_fulldata$improvgroup == "high"], na.rm=TRUE), mean(df_fulldata$error_pre[df_fulldata$cond == "grov" & df_fulldata$improvgroup == "high"], na.rm=TRUE), mean(df_fulldata$error_post[df_fulldata$cond == "grov" & df_fulldata$improvgroup == "high"], na.rm=TRUE))
Con_LowImp <- c(sum(df_fulldata$cond == "kon" & df_fulldata$improvgroup == "low", na.rm=TRUE), mean(df_fulldata$K_pre[df_fulldata$cond == "kon" & df_fulldata$improvgroup == "low"], na.rm=TRUE), mean(df_fulldata$K_post[df_fulldata$cond == "kon" & df_fulldata$improvgroup == "low"], na.rm=TRUE), mean(df_fulldata$error_pre[df_fulldata$cond == "kon" & df_fulldata$improvgroup == "low"], na.rm=TRUE), mean(df_fulldata$error_post[df_fulldata$cond == "kon" & df_fulldata$improvgroup == "low"], na.rm=TRUE))
Con_HighImp <- c(sum(df_fulldata$cond == "kon" & df_fulldata$improvgroup == "high", na.rm=TRUE), mean(df_fulldata$K_pre[df_fulldata$cond == "kon" & df_fulldata$improvgroup == "high"], na.rm=TRUE), mean(df_fulldata$K_post[df_fulldata$cond == "kon" & df_fulldata$improvgroup == "high"], na.rm=TRUE), mean(df_fulldata$error_pre[df_fulldata$cond == "kon" & df_fulldata$improvgroup == "high"], na.rm=TRUE), mean(df_fulldata$error_post[df_fulldata$cond == "kon" & df_fulldata$improvgroup == "high"], na.rm=TRUE))
df_desc <- data.frame(rbind(Int_LowRank, Int_HighRank, Con_LowRank, Con_HighRank, Int_LowImp, Int_HighImp, Con_LowImp, Con_HighImp))
colnames(df_desc) <- c("N", "K Pre", "K Post", "Error Pre", "Error Post")
kable(df_desc)
#the data has to be rearranged
K_pre <- select(df_fulldata, K_pre, cond, ID, laesesubgruppe, improvement)
K_pre$t <- 1
K_pre$improvgroup[K_pre$improvement < 1] <- "low"
K_pre$improvgroup[K_pre$improvement > 0] <- "high"
colnames(K_pre)[1] <- "K"
K_post <- select(df_fulldata, K_post, cond, ID, laesesubgruppe, improvement)
K_post$t <- 2
K_post$improvgroup[K_post$improvement < 1] <- "low"
K_post$improvgroup[K_post$improvement > 0] <- "high"
colnames(K_post)[1] <- "K"
df_K_plot <- bind_rows(K_pre, K_post)
pirateplot(formula = K~t+cond+laesesubgruppe, #which variables are you using
data = df_K_plot,
theme = 0, #check out different themes in the guide page linked at the top, theme 0 is starting from scratch
main = "", #title of the graph
par(cex.main = 1.2), #set the size of your title
xlab="Intervention Group Pre and Post", #label of the x axis
ylab="K", #label of the y axis
cex.lab = 1.2, #size of the axis labels
pal = "basel", # color palette, look at the instruction link to identify different palettes
inf.method = 'hdi', # method of inference - either High Density Interval (hdi, from Bayesian stats), or standard Confidence Interval (ci)
bean.f.o = 0.5, # Bean fill darkness
point.o = .3, # points darkness
inf.f.o = .5, # Inference fill
inf.b.o = .5, # Inference border
avg.line.o = 0.7, # Average line darkness
inf.f.col = "white", # Inf fill col
inf.b.col = "black", # Inf border col
avg.line.col = "black", # avg line col
point.pch = 20, #point shape
point.col = "black", #point colour
point.cex = 1, #point size
gl.col = "#FFFFFF", #gridlines and colour
yaxt ="n", # remove the automatic scale on the axis Y
quant = c(.05, .95)#set the quantile, here within 5% on each side to indicate outliers
)
axis(2, at = seq(1, 3, by = 0.5)) #set the numbers on the y axis
#run this on K delta value instead to make it less confusing
df_fulldata$K_delta <- df_fulldata$K_post - df_fulldata$K_pre
K_test <- aov(K_delta ~ cond*laesesubgruppe, data = df_fulldata)
summary(K_test)
t.test(df_fulldata$K_delta[df_fulldata$cond == "grov" & df_fulldata$laesesubgruppe == "high"], df_fulldata$K_delta[df_fulldata$cond == "grov" & df_fulldata$laesesubgruppe == "low"])
pirateplot(formula = K~t+cond+improvgroup, #which variables are you using
data = df_K_plot,
theme = 0, #check out different themes in the guide page linked at the top, theme 0 is starting from scratch
main = "", #title of the graph
par(cex.main = 1.2), #set the size of your title
xlab="Intervention Group Pre and Post", #label of the x axis
ylab="K", #label of the y axis
cex.lab = 1.2, #size of the axis labels
pal = "basel", # color palette, look at the instruction link to identify different palettes
inf.method = 'hdi', # method of inference - either High Density Interval (hdi, from Bayesian stats), or standard Confidence Interval (ci)
bean.f.o = 0.5, # Bean fill darkness
point.o = .3, # points darkness
inf.f.o = .5, # Inference fill
inf.b.o = .5, # Inference border
avg.line.o = 0.7, # Average line darkness
inf.f.col = "white", # Inf fill col
inf.b.col = "black", # Inf border col
avg.line.col = "black", # avg line col
point.pch = 20, #point shape
point.col = "black", #point colour
point.cex = 1, #point size
gl.col = "#FFFFFF", #gridlines and colour
yaxt ="n", # remove the automatic scale on the axis Y
quant = c(.05, .95) #set the quantile, here within 5% on each side to indicate outliers
)
axis(2, at = seq(1, 3, by = 0.5)) #set the numbers on the y axis
K_test <- aov(K_delta ~ cond*improvgroup, data = df_fulldata)
summary(K_test)
t.test(df_fulldata$K_delta[df_fulldata$cond == "grov" & df_fulldata$improvgroup == "high"], df_fulldata$K_delta[df_fulldata$cond == "grov" & df_fulldata$improvgroup == "low"])
t.test(df_fulldata$K_delta[df_fulldata$cond == "grov" & df_fulldata$improvgroup == "high"], df_fulldata$K_delta[df_fulldata$cond == "grov" & df_fulldata$improvgroup == "low"])
t.test(df_fulldata$K_delta[df_fulldata$cond == "grov" & df_fulldata$improvgroup == "high"], df_fulldata$K_delta[df_fulldata$cond == "kon" & df_fulldata$improvgroup == "high"])
setwd("I:/SCIENCE-NEXS-neurolab/PROJECTS/PLAYMORE/EEG_project1/Analyses/Data")
df <- read.csv('removed_trials.csv')
library(tidyr)
View(df)
df <- filter(df$subjects != c(1001, 1010, 1017, 1023, 1026))
df <- filter(df, subjects != c(1001, 1010, 1017, 1023, 1026))
library(tidyr)
df <- filter(df, subjects != c(1001, 1010, 1017, 1023, 1026))
knitr::opts_chunk$set(echo = FALSE, eval = TRUE, warning = FALSE, message = FALSE)
Sys.setenv(lang = "en_UK")
df <- filter(df, subjects != c(1001, 1010, 1017, 1023, 1026))
?filter
df <- select(df, subjects != c(1001, 1010, 1017, 1023, 1026))
df$subjects != c(1001, 1010, 1017, 1023, 1026)
df <- df$subjects != c(1001, 1010, 1017, 1023, 1026))
df <- df$subjects != c(1001, 1010, 1017, 1023, 1026)
df <- df[df$subjects != c(1001, 1010, 1017, 1023, 1026)]
df <- read.csv('removed_trials.csv')
df <- df[df$subjects != c(1001, 1010, 1017, 1023, 1026)]
c(1001, 1010, 1017, 1023, 1026)
[1001, 1010, 1017, 1023, 1026]
1001, 1010, 1017, 1023, 1026
df <- filter(!df %in% c(1001, 1010, 1017, 1023, 1026))
df <- dplyr::filter(!df %in% c(1001, 1010, 1017, 1023, 1026))
df <- dplyr::filter(!df$subjects %in% c(1001, 1010, 1017, 1023, 1026))
df <- dplyr::filter(df %in% c(1001, 1010, 1017, 1023, 1026))
df <- dplyr::filter(df, subjects == c(1001, 1010, 1017, 1023, 1026))
df <- read.csv('removed_trials.csv')
df <- dplyr::filter(df, subjects == c(1001, 1010, 1017, 1023, 1026))
df <- read.csv('removed_trials.csv')
df <- dplyr::filter(df, subjects == c(1001, 1010, 1017, 1023, 1026))
df <- read.csv('removed_trials.csv')
df <- dplyr::filter(df, subjects != c(1001, 1010, 1017, 1023, 1026))
df <- read.csv('removed_trials.csv')
df <- dplyr::filter(df, subjects != c(1001, 1010, 1017, 1023, 1026))
df <- read.csv('removed_trials.csv')
df <- (!df$subjects == c(1001, 1010, 1017, 1023, 1026))
df <- read.csv('removed_trials.csv')
df <- df[!df$subjects == c(1001, 1010, 1017, 1023, 1026)]
df %>% dplyr::filter(subjects != 1001, subjects != 1010, subjects != 1017, subjects != 1023, subjects != 1026)
df <- read.csv('removed_trials.csv')
df %>% dplyr::filter(subjects != 1001, subjects != 1010, subjects != 1017, subjects != 1023, subjects != 1026)
df <- df %>% dplyr::filter(subjects != 1001, subjects != 1010, subjects != 1017, subjects != 1023, subjects != 1026)
df$pre_total <- sum(df$pre_processing, df$pre_ica)
df$pre_total <- sum(df$pre_processing, df$pre_ica)
df$post_total <- sum(df$post_processing, df$post_ica)
df$int_total <- sum(df$int_processing, df$int_ica)
df$pre_total <- sum(df$pre_processing + df$pre_ica)
df$post_total <- sum(df$post_processing + df$post_ica)
df$int_total <- sum(df$int_processing + df$int_ica)
df$pre_total <- df$pre_processing + df$pre_ica
df$pre_total <- df$pre_processing + df$pre_ica
df$post_total <- df$post_processing + df$post_ica
df$int_total <- df$int_processing + df$int_ica
df$int_processing
df$int_total <- df$int_preprocessing + df$int_ica
df$pre_total <- df$pre_processing + df$pre_ica + df$pre_remaining
df$post_total <- df$post_processing + df$post_ica + df$post_remaining
df$int_total <- df$int_preprocessing + df$int_ica + df$int_remaining
df$all_total <- df$pre_total + df$post_total + df$int_total
df$all_rejected <- df$pre_processing + df$pre_ica + df$post_processing + df$post_ica + df$int_preprocessing + df$int_ica
(df$all_rejected/df$all_total)*100
df$prcnt_rejected <- (df$all_rejected/df$all_total)*100
mean(df$prcnt_rejected[df$group == 1])
mean(df$prcnt_rejected[df$group == 2])
?t.test
t.test(df$prcnt_rejected ~ df$group)
mean(df$prcnt_rejected[df$grade == 1])
mean(df$prcnt_rejected[df$grade == 0])
t.test(df$prcnt_rejected ~ df$grade)
