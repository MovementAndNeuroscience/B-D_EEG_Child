?write.csv
write.csv(acc_data, file = "accuracy_data.csv")
setwd('I:/SCIENCE-NEXS-neurolab/PROJECTS/PLAYMORE/EEG_project1/Analyses/B-D_EEG_Repo/Results')
acc_data <- select(df_inc_acc, Train_acc_cor, ID, Cond)
write.csv(acc_data, file = "accuracy_data.csv")
install.packages("remotes")
remotes::install_github("joereinhardt/BayesianFirstAid-Wilcoxon")
install.packages("jmv")
knitr::opts_chunk$set(echo = FALSE, eval = TRUE, warning = FALSE, message = FALSE)
library(jmV)
setwd("I:/SCIENCE-NEXS-neurolab/PROJECTS/PLAYMORE/EEG_project1/Analyses")
library(tidyverse)
library(knitr)
library(yarrr)
library(jmv)
Sys.setenv(lang = "en_UK")
#read all data
df <- read.csv('all_subjects.csv')
#select those who meet inclusion critera
df_inc <- filter(df, Included_an1 == 1)
bugs = bugs
bugs = 'bugs'
rm(bugs)
bugs <- bugs
data('bugs', package = 'jmv')
ttestPS(bugs, pairs = list(
list(i1 = 'LDLF', i2 = 'LDHF')))
View(bugs)
View(df_inc)
View(df_inc)
rm(bugs)
ttestIS(formula = Train_acc ~ Con, data = df_inc)
ttestIS(formula = Train_acc ~ Cond, data = df_inc)
write.csv(acc_data, file = "accuracy_data.csv", mann = TRUE)
ttestIS(formula = Train_acc ~ Cond, data = df_inc, MANN = true)
ttestIS(formula = Train_acc ~ Cond, data = df_inc, mann = TRUE)
ttestIS(formula = Train_acc ~ Cond, data = df_inc, mann = TRUE, bf = TRUE)
ttestIS(formula = Train_acc ~ Cond, data = df_inc, mann = TRUE, bf = TRUE, effectSize = TRUE)
#correct the RT and Acc data
#Accuracy
regr = df_inc$Age #this is the confound
dat = df_inc$Train_acc #this is the data that should be corrected
# B = X\Y (beta estimate)
beta = regr / dat
# Model = X*X\Y
model = regr * beta
# Y clean
Yclean = dat - model
df_inc$Train_acc_cor <- Yclean
#RT
regr = df_inc$Age #this is the confound
dat = df_inc$Train_corr_RT #this is the data that should be corrected
# B = X\Y (beta estimate)
beta = regr / dat
# Model = X*X\Y
model = regr * beta
# Y clean
Yclean = dat - model
df_inc$Train_corr_RT_cor <- Yclean
#DT
regr = df_inc$Age #this is the confound
dat = df_inc$Train_corr_DT #this is the data that should be corrected
# B = X\Y (beta estimate)
beta = regr / dat
# Model = X*X\Y
model = regr * beta
# Y clean
Yclean = dat - model
df_inc$Train_corr_DT_cor <- Yclean
#select the data for accuracy and rt
#df_inc_acc <- filter(df_inc, Train_eprime_acc_reliability == "1")
df_inc_acc <- df_inc
df_inc_rt <- filter(df_inc, Train_eprime_rt_reliability == "1")
`Training Accuracy Median` <- c(median(df_inc$Train_acc_cor[df_inc$Cond == "TS"]), median(df_inc$Train_acc_cor[df_inc$Cond == "ET"]))
`Training Accuracy Min` <- c(min(df_inc$Train_acc_cor[df_inc$Cond == "TS"]), min(df_inc$Train_acc_cor[df_inc$Cond == "ET"]))
`Training Accuracy Max` <- c(max(df_inc$Train_acc_cor[df_inc$Cond == "TS"]), max(df_inc$Train_acc_cor[df_inc$Cond == "ET"]))
`Training Correct RT` <- c(median(df_inc$Train_corr_RT_cor[df_inc$Cond == "TS" & df_inc$Train_eprime_rt_reliability == 1]), median(df_inc$Train_corr_RT_cor[df_inc$Cond == "ET"]))
`Training Correct DT` <- c(median(df_inc$Train_corr_DT_cor[df_inc$Cond == "TS" & df_inc$Train_eprime_rt_reliability == 1]), median(df_inc$Train_corr_DT_cor[df_inc$Cond == "ET"]))
training <- as.data.frame(rbind(`Training Accuracy Median`, `Training Accuracy Min`, `Training Accuracy Max`, `Training Correct RT`, `Training Correct DT`))
colnames(training) <- c('Touch Screen', 'Eye Tracker')
kable(training, digits = 2)
ttestIS(formula = Train_acc_cor ~ Cond, data = df_inc, mann = TRUE, bf = TRUE, effectSize = TRUE)
int_RT_TS <- df_inc$Train_corr_RT_cor[df_inc$Cond == 'TS' & df_inc$Train_eprime_rt_reliability == 1]
int_RT_ET <- df_inc$Train_corr_RT_cor[df_inc$Cond == 'ET']
int_RT_test <- wilcox.test(int_RT_TS, int_RT_ET)
int_RT_test
ttestIS(vars = int_RT_TS, vars = int_RT_ET, data = df_inc, mann = TRUE, bf = TRUE, effectSize = TRUE)
ttestIS(vars = c(int_RT_TS, int_RT_TS), data = df_inc, mann = TRUE, bf = TRUE, effectSize = TRUE)
View(df_inc)
ttestIS(formula = Train_corr_RT_cor[df_inc$Train_eprime_rt_reliability == 1] ~ Cond, data = df_inc, mann = TRUE, bf = TRUE, effectSize = TRUE)
ttestIS(formula = df_inc$Train_corr_RT_cor[df_inc$Train_eprime_rt_reliability == 1] ~ Cond, data = df_inc, mann = TRUE, bf = TRUE, effectSize = TRUE)
#Bayesian stats
bayes_rt <- select(df_inc, df_inc$Train_eprime_rt_reliability = 1)
#Bayesian stats
bayes_rt <- select(df_inc, df_inc$Train_eprime_rt_reliability == 1)
acc_data <- filter(df_inc_acc, Train_acc_cor, ID, Cond)
#Bayesian stats
bayes_rt <- select(df_inc, Train_eprime_rt_reliability == 1)
#Bayesian stats
bayes_rt <- select(df_inc, Train_eprime_rt_reliability = 1)
View(bayes_rt)
#Bayesian stats
bayes_rt <- filter(df_inc, Train_eprime_rt_reliability = 1)
#Bayesian stats
bayes_rt <- filter(df_inc, Train_eprime_rt_reliability == 1)
ttestIS(formula = Train_corr_RT_cor ~ Cond, data = bayes_rt, mann = TRUE, bf = TRUE, effectSize = TRUE)
int_DT_TS <- df_inc$Train_corr_DT_cor[df_inc$Cond == 'TS' & df_inc$Train_eprime_rt_reliability == 1]
int_DT_ET <- df_inc$Train_corr_DT_cor[df_inc$Cond == 'ET']
int_DT_test <- wilcox.test(int_DT_TS, int_DT_ET)
int_DT_test
ttestIS(formula = Train_corr_DT_cor ~ Cond, data = bayes_rt, mann = TRUE, bf = TRUE, effectSize = TRUE)
int_DT_test <- ttestIS(formula = Train_corr_DT_cor ~ Cond, data = bayes_rt, mann = TRUE, bf = TRUE, effectSize = TRUE)
int_DT_test
int_DT_test$ttest
View(int_RT_test)
int_DT_test$p.value
int_DT_test
int_DT_test$asDF
int_DT_test$asString
x = c(1 2 3)
x <- c(1 2 3)
x <- c(1, 2, 3)
p.adjust(c(0.0209436, 0.0417832, 0.6064685), method = "BH")
x <- c(0.0209436, 0.0417832, 0.6064685)
p.adjust(x, method = "BH")
p.adjust(c(0.0417832, 0.6064685, 0.0209436), method = "BH")
IQR(df_inc$Train_acc_cor[df_inc$Cond == "TS"])
median(df_inc$Train_acc_cor[df_inc$Cond == "TS"])
median(df_inc$Train_acc_cor[df_inc$Cond == "ET"])
IQR(df_inc$Train_acc_cor[df_inc$Cond == "ET"])
pirateplot(formula = Train_corr_DT~Cond, #which variables are you using
data = bayes_rt,
theme = 0, #check out different themes in the guide page linked at the top, theme 0 is starting from scratch
main = "Intervention Correct DT", #title of the graph
par(cex.main = 1.2), #set the size of your title
xlab="Intervention Group", #label of the x axis
ylab="DT ms", #label of the y axis
cex.lab = 1.2, #size of the axis labels
pal = "basel", # color palette, look at the instruction link to identify different palettes
inf.method = 'hdi', # method of inference - either High Density Interval (hdi, from Bayesian stats), or standard Confidence Interval (ci)
bean.f.o = 0.5, # Bean fill darkness
point.o = .3, # points darkness
inf.f.o = .5, # Inference fill
inf.b.o = .5, # Inference border
avg.line.o = 0.7, # Average line darkness
inf.f.col = "white", # Inf fill col
inf.b.col = "black", # Inf border col
avg.line.col = "black", # avg line col
point.pch = 20, #point shape
point.col = "black", #point colour
point.cex = 1, #point size
gl.col = "#FFCCFF", #gridlines and colour
yaxt ="n", # remove the automatic scale on the axis Y
quant = c(.05, .95) #set the quantile, here within 5% on each side to indicate outliers
)
axis(2, at = seq(1300, 2900, by = 400)) #set the numbers on the y axis
#got to get rid of the two participants with unreliable data
df_inc_RT <- filter(df_inc, Train_eprime_rt_reliability == 1)
pirateplot(formula = Train_corr_RT~Cond, #which variables are you using
data = bayes_rt,
theme = 0, #check out different themes in the guide page linked at the top, theme 0 is starting from scratch
main = "Intervention Correct RT", #title of the graph
par(cex.main = 1.2), #set the size of your title
xlab="Intervention Group", #label of the x axis
ylab="RT ms", #label of the y axis
cex.lab = 1.2, #size of the axis labels
pal = "basel", # color palette, look at the instruction link to identify different palettes
inf.method = 'hdi', # method of inference - either High Density Interval (hdi, from Bayesian stats), or standard Confidence Interval (ci)
bean.f.o = 0.5, # Bean fill darkness
point.o = .3, # points darkness
inf.f.o = .5, # Inference fill
inf.b.o = .5, # Inference border
avg.line.o = 0.7, # Average line darkness
inf.f.col = "white", # Inf fill col
inf.b.col = "black", # Inf border col
avg.line.col = "black", # avg line col
point.pch = 20, #point shape
point.col = "black", #point colour
point.cex = 1, #point size
gl.col = "#FFCCFF", #gridlines and colour
yaxt ="n", # remove the automatic scale on the axis Y
quant = c(.05, .95) #set the quantile, here within 5% on each side to indicate outliers
)
axis(2, at = seq(1600, 3500, by = 400)) #set the numbers on the y axis
x <- c(0.652, 0.004, 0.496, 0.039)
p.adjust(x, method = 'bh')
p.adjust(x, method = 'BH')
x <- c(0.652, 0.004, 0.496, 0.039, 0.0078, 0.0078)
p.adjust(x, method = 'BH')
x <-  c(13.6766, -1.1865, 4.4405, 3.9619, 5.0968, 8.0542, 5.9008, 11.3613,7.1090)
y <- c(16.1563, 16.2117,  1.2864, 8.1584, 9.6340, 13.2510, -0.9280, 17.4865, 5.5705)
df <- as.data.frame(cbind(x, y))
View(df)
ttestOneS(df, vars = vars(x, y))
library(jmv)
ttestOneS(df, vars = vars(x, y))
ttestOneS(df, vars = vars(x, y), wilcoxon = TRUE)
ttestOneS(df, vars = vars(x, y), wilcoxon = TRUE, bf = TRUE)
x <-  c(2.554662343, 3.463501066, -1.682635818, 0.696339791, -1.583880524, -1.702933044, 4.5241343, 0.188014023, -1.806626398)
y <- c(0.420840058, 5.858109461, 7.525084173, 3.904204782, 1.339609221, 3.896945925, 0.291344569, 7.17596151, 1.264270503)
df <- as.data.frame(cbind(x, y))
ttestOneS(df, vars = vars(x, y), wilcoxon = TRUE, bf = TRUE)
x <-  c(-1.140060533, -3.815308496, -1.03578447, 2.427276925, 4.040882188, 7.140101039, -2.290872169, 9.228034077, -2.231545158)
y <- c(-9.252864603, -0.984561985, -7.064422805, -0.824971247, -0.235487285, 0.238642391, -3.074680244, 0.355551628, -4.259405848)
df <- as.data.frame(cbind(x, y))
ttestOneS(df, vars = vars(x, y), wilcoxon = TRUE, bf = TRUE)
x <- c(0.652, 0.004, 0.496, 0.039, 0.0078, 0.0078)
x/2
x <- x/2
p.adjust(x, method = 'BH')
knitr::opts_chunk$set(echo = FALSE, eval = TRUE, warning = FALSE, message = FALSE)
setwd("I:/SCIENCE-NEXS-neurolab/PROJECTS/PLAYMORE/EEG_project1/Analyses")
library(tidyverse)
library(knitr)
library(yarrr)
library(jmv)
Sys.setenv(lang = "en_UK")
#read all data
df <- read.csv('all_subjects.csv')
#select those who meet inclusion critera
df_inc <- filter(df, Included_an1 == 1)
#In this chunk I create all objects that will be displayed in my table, my table will have two columns so each object needs to have two numbers
N_TS <- sum(df_inc$Cond == "TS") #callculate the number of participants in the intervention group
N_ET <- sum(df_inc$Cond == "ET") #callculate the number of participants in the control group
N <- c(sum(df_inc$Cond == "TS"), sum(df_inc$Cond == "ET")) #object 1 - number of all participants
`Age Median` <- c(median(df_inc$Age[df_inc$Cond == "TS"]), median(df_inc$Age[df_inc$Cond == "ET"])) #object2 - age of participants
`Age Min` <- c(min(df_inc$Age[df_inc$Cond == "TS"]), min(df_inc$Age[df_inc$Cond == "ET"])) #object3 - minimum age
`Age Max` <- c(max(df_inc$Age[df_inc$Cond == "TS"]), max(df_inc$Age[df_inc$Cond == "ET"])) #object 4 - maximum age
`Male %` <- c((sum(df_inc$Sex[df_inc$Cond == "TS"] == "M")/N_TS)*100, sum((df_inc$Sex[df_inc$Cond == "ET"] == "M")/N_ET)*100) #object5 - percentage of males
`Female %` <- c((sum(df_inc$Sex[df_inc$Cond == "TS"] == "F")/N_TS)*100, sum((df_inc$Sex[df_inc$Cond == "ET"] == "F")/N_ET)*100) #object6 - percentage of females
`Year 0 %` <- c((sum(df_inc$School_year[df_inc$Cond == "TS"] == 0)/N_TS)*100, sum((df_inc$School_year[df_inc$Cond == "ET"] == 0)/N_ET)*100) #boject7 - percentage of children in grade 0
`Year 1 %` <- c((sum(df_inc$School_year[df_inc$Cond == "TS"] == 1)/N_TS)*100, sum((df_inc$School_year[df_inc$Cond == "ET"] == 1)/N_ET)*100) #object8 - percentage of children in grade 1
`Bilingual %` <- c((sum(df_inc$Bilingual[df_inc$Cond == "TS"] == 1)/N_TS)*100, sum((df_inc$Bilingual[df_inc$Cond == "ET"] == 1)/N_ET)*100) #object9 - percentage of children who are bilingual
`Right Handed %` <- c((sum(df_inc$Dom_hand[df_inc$Cond == "TS"] == "R")/N_TS)*100, sum((df_inc$Dom_hand[df_inc$Cond == "ET"] == "R")/N_ET)*100) #object10 - percentage of children who are righthanded
`Left Handed %` <- c((sum(df_inc$Dom_hand[df_inc$Cond == "TS"] == "L")/N_TS)*100, sum((df_inc$Dom_hand[df_inc$Cond == "ET"] == "L")/N_ET)*100) #object 11 - percentage of children who are lefthanded
demo <- as.data.frame(rbind(N, `Age Median`, `Age Min`, `Age Max`, `Male %`, `Female %`, `Year 0 %`, `Year 1 %`, `Bilingual %`, `Right Handed %`, `Left Handed %`)) #make a data frame with all of the above objects - it should have 11 rows and two columns
colnames(demo) <- c('Touch Screen', 'Eye Tracker') #add column names
kable(demo, digits = 0) #make the table and specify how many decimal places should be displayed
#correct the RT and Acc data
#Accuracy
regr = df_inc$Age #this is the confound
dat = df_inc$Train_acc #this is the data that should be corrected
# B = X\Y (beta estimate)
beta = regr / dat
# Model = X*X\Y
model = regr * beta
# Y clean
Yclean = dat - model
df_inc$Train_acc_cor <- Yclean
#RT
regr = df_inc$Age #this is the confound
dat = df_inc$Train_corr_RT #this is the data that should be corrected
# B = X\Y (beta estimate)
beta = regr / dat
# Model = X*X\Y
model = regr * beta
# Y clean
Yclean = dat - model
df_inc$Train_corr_RT_cor <- Yclean
#DT
regr = df_inc$Age #this is the confound
dat = df_inc$Train_corr_DT #this is the data that should be corrected
# B = X\Y (beta estimate)
beta = regr / dat
# Model = X*X\Y
model = regr * beta
# Y clean
Yclean = dat - model
df_inc$Train_corr_DT_cor <- Yclean
#select the data for accuracy and rt
#df_inc_acc <- filter(df_inc, Train_eprime_acc_reliability == "1")
df_inc_acc <- df_inc
df_inc_rt <- filter(df_inc, Train_eprime_rt_reliability == "1")
`Training Accuracy Median` <- c(median(df_inc$Train_acc_cor[df_inc$Cond == "TS"]), median(df_inc$Train_acc_cor[df_inc$Cond == "ET"]))
`Training Accuracy Min` <- c(min(df_inc$Train_acc_cor[df_inc$Cond == "TS"]), min(df_inc$Train_acc_cor[df_inc$Cond == "ET"]))
`Training Accuracy Max` <- c(max(df_inc$Train_acc_cor[df_inc$Cond == "TS"]), max(df_inc$Train_acc_cor[df_inc$Cond == "ET"]))
`Training Correct RT` <- c(median(df_inc$Train_corr_RT_cor[df_inc$Cond == "TS" & df_inc$Train_eprime_rt_reliability == 1]), median(df_inc$Train_corr_RT_cor[df_inc$Cond == "ET"]))
`Training Correct DT` <- c(median(df_inc$Train_corr_DT_cor[df_inc$Cond == "TS" & df_inc$Train_eprime_rt_reliability == 1]), median(df_inc$Train_corr_DT_cor[df_inc$Cond == "ET"]))
training <- as.data.frame(rbind(`Training Accuracy Median`, `Training Accuracy Min`, `Training Accuracy Max`, `Training Correct RT`, `Training Correct DT`))
colnames(training) <- c('Touch Screen', 'Eye Tracker')
kable(training, digits = 2)
median(df_inc$Train_corr_RT_cor[df_inc$Cond == "TS" & df_inc$Train_eprime_rt_reliability == 1])
median(df_inc$Train_acc_cor[df_inc$Cond == "TS"])
IQR(df_inc$Train_acc_cor[df_inc$Cond == "TS"])
median(df_inc$Train_acc_cor[df_inc$Cond == "ET"])
IQR(df_inc$Train_acc_cor[df_inc$Cond == "ET"])
median(df_inc$Train_corr_RT_cor[df_inc$Cond == "TS" & df_inc$Train_eprime_rt_reliability == 1])
IQR(df_inc$Train_corr_RT_cor[df_inc$Cond == "TS" & df_inc$Train_eprime_rt_reliability == 1])
median(df_inc$Train_corr_RT_cor[df_inc$Cond == "ET"])
IQR(df_inc$Train_corr_RT_cor[df_inc$Cond == "ET"])
median(df_inc$Train_corr_DT_cor[df_inc$Cond == "TS" & df_inc$Train_eprime_rt_reliability == 1])
IQR(df_inc$Train_corr_DT_cor[df_inc$Cond == "TS" & df_inc$Train_eprime_rt_reliability == 1])
median(df_inc$Train_corr_DT_cor[df_inc$Cond == "ET"])
IQR(df_inc$Train_corr_DT_cor[df_inc$Cond == "ET"])
x <- c(0.652, 0.0195, 0.496, 0.039, 0.0078, 0.0078)
x <- x/2
p.adjust(x, method = 'BH')
install.packages("tidyverse")
install.packages("knitr")
install.packages("yarrr")
install.packages("jmv")
install.packages("markdown")
install.packages("rmarkdown")
knitr::opts_chunk$set(echo = FALSE, eval = TRUE, warning = FALSE, message = FALSE)
setwd("I:/SCIENCE-NEXS-neurolab/PROJECTS/PLAYMORE/EEG_project1/Analyses")
library(tidyverse)
library(knitr)
library(yarrr)
library(jmv)
Sys.setenv(lang = "en_UK")
#read all data
df <- read.csv('all_subjects.csv')
#select those who meet inclusion critera
df_inc <- filter(df, Included_an1 == 1)
View(df_inc)
View(df)
View(df)
setwd("I:/SCIENCE-NEXS-neurolab/PROJECTS/PLAYMORE/EEG_project1/Analyses/OSF_files/EEG_behavioural")
library(tidyverse)
library(knitr)
library(yarrr)
library(jmv)
Sys.setenv(lang = "en_UK")
#read all data
df <- read.csv('all_subjects.csv')
#select those who meet inclusion critera
df_inc <- filter(df, Included_an1 == 1)
df_inc$Pre_acc
regr = df_inc$Age #this is the confound
dat = df_inc$Pre_acc #this is the data that should be corrected
# B = X\Y (beta estimate)
beta = regr / dat
# Model = X*X\Y
model = regr * beta
# Y clean
Yclean = dat - model
df_inc$Pre_acc_cor <- Yclean
df_inc$Pre_acc_cor
df_inc$Pre_corr_RT
regr = df_inc$Age #this is the confound
dat = df_inc$Pre_corr_RT #this is the data that should be corrected
# B = X\Y (beta estimate)
beta = regr / dat
# Model = X*X\Y
model = regr * beta
# Y clean
Yclean = dat - model
df_inc$Pre_corr_RT_cor <- Yclean
df_inc$Pre_corr_RT_cor
`Pre Accuracy Median` <- c(median(df_inc$Pre_acc_cor[df_inc$Cond == "TS"]), median(df_inc$Pre_acc_cor[df_inc$Cond == "ET"]))
`Pre Accuracy Min` <- c(min(df_inc$Pre_acc_cor[df_inc$Cond == "TS"]), min(df_inc$Pre_acc_cor[df_inc$Cond == "ET"]))
`Pre Accuracy Max` <- c(max(df_inc$Pre_acc_cor[df_inc$Cond == "TS"]), max(df_inc$Pre_acc_cor[df_inc$Cond == "ET"]))
`Pre Correct RT` <- c(median(df_inc$Pre_corr_RT_cor[df_inc$Cond == "TS"]), median(df_inc$Pre_corr_RT_cor[df_inc$Cond == "ET"]))
Pre <- as.data.frame(rbind(`Pre Accuracy Median`, `Pre Accuracy Min`, `Pre Accuracy Max`, `Pre Correct RT`))
colnames(Pre) <- c('Touch Screen', 'Eye Tracker')
kable(Pre, digits = 2)
#!!!!!!!!! - Might want to change word to vertical view after knitting the document because the table doesn't fit very well
#Statistics
ttestIS(formula = Pre_acc_cor ~ Cond, data = df_inc, mann = TRUE, bf = TRUE, effectSize = TRUE)
#Statistics
ttestIS(formula = Pre_corr_RT_cor ~ Cond, data = df_inc, mann = TRUE, bf = TRUE, effectSize = TRUE)
p.adjust(c(0.2686996, 0.0244344), method = "BH")
library(tidyr)
setwd('I:/SCIENCE-NEXS-neurolab/PROJECTS/PLAYMORE/EEG_project1/Analyses/B-D_EEG_Repo/Results')
df_channels <- read.csv('allBadchannels.csv', col.names = c('subjects', 'int_n', 'chan_1', 'chan_2', 'chan_3', 'chan_4', 'chan_5', 'chan_6', 'chan_7'))
df_trials <- read.csv('allRemovedTrials.csv')
# Load the data for channels and trials and subjects
df_channels <- read.csv('allBadchannels.csv', col.names = c('subjects', 'int_n', 'chan_1', 'chan_2', 'chan_3', 'chan_4', 'chan_5', 'chan_6', 'chan_7', 'chan_8', 'chan_9', 'chan_10', 'chan_11', 'chan_12', 'chan_13', 'chan_14'))
# Load the data for channels and trials and subjects
df_channels <- read.csv('allBadchannels.csv')#, col.names = c('subjects', 'int_n', 'chan_1', 'chan_2', 'chan_3', 'chan_4', 'chan_5', 'chan_6', 'chan_7', 'chan_8', 'chan_9', 'chan_10', 'chan_11', 'chan_12', 'chan_13', 'chan_14'))
View(df_channels)
rm(df_channels)
# Load the data for channels and trials and subjects
df_channels <- read.csv('allBadchannels.csv', col.names = c('subjects', 'int_n', 'chan_1', 'chan_2', 'chan_3', 'chan_4', 'chan_5', 'chan_6', 'chan_7', 'chan_8', 'chan_9', 'chan_10', 'chan_11', 'chan_12', 'chan_13', 'chan_14'))
rm(df_channels)
# Load the data for channels and trials and subjects
df_channels <- read.csv('allBadchannels.csv', col.names = c('subjects', 'int_n', 'chan_1', 'chan_2', 'chan_3', 'chan_4', 'chan_5', 'chan_6', 'chan_7', 'chan_8', 'chan_9', 'chan_10', 'chan_11', 'chan_12', 'chan_13', 'chan_14', 'chan_15'))
setwd('I:/SCIENCE-NEXS-neurolab/PROJECTS/PLAYMORE/EEG_project1/Analyses/B-D_EEG_Repo')
library("readxl")
df_subjects <- read_excel("subjects.xlsx")
df_channels$cond <- df_subjects$int
df_trials$cond <- df_subjects$int
df_channels <- df_channels %>% dplyr::filter(subjects != 'sub-07', subjects != 'sub-12', subjects != 'sub-17')
df_trials <- df_trials %>% dplyr::filter(subjects != 'sub-07', subjects != 'sub-12', subjects != 'sub-17')
# Load the data for channels and trials and subjects
df_channels <- read.csv('allBadchannels.csv', col.names = c('subjects','pre_n', 'int_n', 'chan_1', 'chan_2', 'chan_3', 'chan_4', 'chan_5', 'chan_6', 'chan_7', 'chan_8', 'chan_9', 'chan_10', 'chan_11', 'chan_12', 'chan_13', 'chan_14'))
setwd('I:/SCIENCE-NEXS-neurolab/PROJECTS/PLAYMORE/EEG_project1/Analyses/B-D_EEG_Repo/Results')
# Load the data for channels and trials and subjects
df_channels <- read.csv('allBadchannels.csv', col.names = c('subjects','pre_n', 'int_n', 'chan_1', 'chan_2', 'chan_3', 'chan_4', 'chan_5', 'chan_6', 'chan_7', 'chan_8', 'chan_9', 'chan_10', 'chan_11', 'chan_12', 'chan_13', 'chan_14'))
df_trials <- read.csv('allRemovedTrials.csv')
library(tidyr)
setwd('I:/SCIENCE-NEXS-neurolab/PROJECTS/PLAYMORE/EEG_project1/Analyses/B-D_EEG_Repo/Results')
# Load the data for channels and trials and subjects
df_channels <- read.csv('allBadchannels.csv', col.names = c('subjects','pre_n', 'int_n', 'chan_1', 'chan_2', 'chan_3', 'chan_4', 'chan_5', 'chan_6', 'chan_7', 'chan_8', 'chan_9', 'chan_10', 'chan_11', 'chan_12', 'chan_13', 'chan_14'))
df_trials <- read.csv('allRemovedTrials.csv')
setwd('I:/SCIENCE-NEXS-neurolab/PROJECTS/PLAYMORE/EEG_project1/Analyses/B-D_EEG_Repo')
library("readxl")
df_subjects <- read_excel("subjects.xlsx")
# Mark intervention groups in the channel and trials datasets
df_channels$cond <- df_subjects$int
df_trials$cond <- df_subjects$int
#Remove participants who were not included in analyses
df_channels <- df_channels %>% dplyr::filter(subjects != 'sub-07', subjects != 'sub-12', subjects != 'sub-17')
df_trials <- df_trials %>% dplyr::filter(subjects != 'sub-07', subjects != 'sub-12', subjects != 'sub-17')
chans_ET_mean <- mean(df_channels$int_n[df_channels$cond == 'ET'])
chans_TS_mean <- mean(df_channels$int_n[df_channels$cond == 'TS'])
chans_ET_median <- median(df_channels$int_n[df_channels$cond == 'ET'])
chans_TS_median <- median(df_channels$int_n[df_channels$cond == 'TS'])
chans_ET_sd <- sd(df_channels$int_n[df_channels$cond == 'ET'])
chans_TS_sd <- sd(df_channels$int_n[df_channels$cond == 'TS'])
chans_ET_IQR <- IQR(df_channels$int_n[df_channels$cond == 'ET'])
chans_TS_IQR <- IQR(df_channels$int_n[df_channels$cond == 'TS'])
wilcox.test(df_channels$int_n[df_channels$cond == 'ET'], df_channels$int_n[df_channels$cond == 'TS'], alternative = "two.sided")
#remove empty rows
df_channels[rowSums(is.na(df_channels)) == 0,]
#remove empty rows
df_channels <- df_channels[rowSums(is.na(df_channels)) == 0,]
chans_ET_mean <- mean(df_channels$int_n[df_channels$cond == 'ET'])
chans_TS_mean <- mean(df_channels$int_n[df_channels$cond == 'TS'])
chans_ET_median <- median(df_channels$int_n[df_channels$cond == 'ET'])
chans_TS_median <- median(df_channels$int_n[df_channels$cond == 'TS'])
chans_ET_sd <- sd(df_channels$int_n[df_channels$cond == 'ET'])
chans_TS_sd <- sd(df_channels$int_n[df_channels$cond == 'TS'])
chans_ET_IQR <- IQR(df_channels$int_n[df_channels$cond == 'ET'])
chans_TS_IQR <- IQR(df_channels$int_n[df_channels$cond == 'TS'])
wilcox.test(df_channels$int_n[df_channels$cond == 'ET'], df_channels$int_n[df_channels$cond == 'TS'], alternative = "two.sided")
pre_chans_ET_mean <- mean(df_channels$pre_n[df_channels$cond == 'ET'])
pre_chans_TS_mean <- mean(df_channels$pre_n[df_channels$cond == 'TS'])
pre_chans_ET_median <- median(df_channels$pre_n[df_channels$cond == 'ET'])
pre_chans_TS_median <- median(df_channels$pre_n[df_channels$cond == 'TS'])
pre_chans_ET_sd <- sd(df_channels$pre_n[df_channels$cond == 'ET'])
pre_chans_TS_sd <- sd(df_channels$pre_n[df_channels$cond == 'TS'])
pre_chans_ET_IQR <- IQR(df_channels$pre_n[df_channels$cond == 'ET'])
pre_chans_TS_IQR <- IQR(df_channels$pre_n[df_channels$cond == 'TS'])
wilcox.test(df_channels$pre_n[df_channels$cond == 'ET'], df_channels$pre_n[df_channels$cond == 'TS'], alternative = "two.sided")
f_channels$pre_n
df_channels$pre_n
mean(df_channels$pre_n
)
View(df_trials)
df_trials$total <- df_trials$int_preprocessing + df_trials$int_ica + df_trials$int_remaining
df_trials$all_removed <- df_trials$int_preprocessing + df_trials$int_ica
trials_all_removed_ET_mean <- mean(df_trials$all_removed[df_trials$cond == 'ET'])
trials_all_removed_TS_mean <- mean(df_trials$all_removed[df_trials$cond == 'TS'])
trials_all_removed_ET_median <- median(df_trials$all_removed[df_trials$cond == 'ET'])
trials_all_removed_TS_median <- median(df_trials$all_removed[df_trials$cond == 'TS'])
trials_all_removed_ET_sd <- sd(df_trials$all_removed[df_trials$cond == 'ET'])
trials_all_removed_TS_sd <- sd(df_trials$all_removed[df_trials$cond == 'TS'])
trials_all_removed_ET_IQR <- IQR(df_trials$all_removed[df_trials$cond == 'ET'])
trials_all_removed_TS_IQR <- IQR(df_trials$all_removed[df_trials$cond == 'TS'])
wilcox.test(df_trials$all_removed[df_trials$cond == 'ET'], df_trials$all_removed[df_trials$cond == 'TS'], alternative = "two.sided")
View(df_channels)
View(df_trials)
View(df_channels)
mean(df_trials$int_remaining[df_trials$cond == 'ET'])
mean(df_trials$int_remaining[df_trials$cond == 'TS'])
df_trials$total <- df_trials$int_preprocessing + df_trials$int_ica + df_trials$int_remaining
df_trials$all_removed <- df_trials$int_preprocessing + df_trials$int_ica
trials_all_removed_ET_mean <- mean(df_trials$all_removed[df_trials$cond == 'ET'])
trials_all_removed_TS_mean <- mean(df_trials$all_removed[df_trials$cond == 'TS'])
trials_all_removed_ET_median <- median(df_trials$all_removed[df_trials$cond == 'ET'])
trials_all_removed_TS_median <- median(df_trials$all_removed[df_trials$cond == 'TS'])
trials_all_removed_ET_sd <- sd(df_trials$all_removed[df_trials$cond == 'ET'])
trials_all_removed_TS_sd <- sd(df_trials$all_removed[df_trials$cond == 'TS'])
trials_all_removed_ET_IQR <- IQR(df_trials$all_removed[df_trials$cond == 'ET'])
trials_all_removed_TS_IQR <- IQR(df_trials$all_removed[df_trials$cond == 'TS'])
wilcox.test(df_trials$all_removed[df_trials$cond == 'ET'], df_trials$all_removed[df_trials$cond == 'TS'], alternative = "two.sided")
df_trials$pre_total <- df_trials$pre__preprocessing + df_trials$pre__ica + df_trials$pre__remaining
df_trials$pre_removed <- df_trials$pre__preprocessing + df_trials$pre_ica
pre_trials_all_removed_ET_mean <- mean(df_trials$pre_removed[df_trials$cond == 'ET'])
pre_trials_all_removed_TS_mean <- mean(df_trials$pre_removed[df_trials$cond == 'TS'])
pre_trials_all_removed_ET_median <- median(df_trials$pre_removed[df_trials$cond == 'ET'])
pre_trials_all_removed_TS_median <- median(df_trials$pre_removed[df_trials$cond == 'TS'])
pre_trials_all_removed_ET_sd <- sd(df_trials$pre__removed[df_trials$cond == 'ET'])
pre_trials_all_removed_TS_sd <- sd(df_trials$pre__removed[df_trials$cond == 'TS'])
pre_trials_all_removed_ET_IQR <- IQR(df_trials$pre__removed[df_trials$cond == 'ET'])
pre_trials_all_removed_TS_IQR <- IQR(df_trials$pre__removed[df_trials$cond == 'TS'])
df_trials$pre_total <- df_trials$pre_preprocessing + df_trials$pre__ica + df_trials$pre_remaining
df_trials$pre_removed <- df_trials$pre_preprocessing + df_trials$pre_ica
pre_trials_all_removed_ET_mean <- mean(df_trials$pre_removed[df_trials$cond == 'ET'])
pre_trials_all_removed_TS_mean <- mean(df_trials$pre_removed[df_trials$cond == 'TS'])
pre_trials_all_removed_ET_median <- median(df_trials$pre_removed[df_trials$cond == 'ET'])
pre_trials_all_removed_TS_median <- median(df_trials$pre_removed[df_trials$cond == 'TS'])
pre_trials_all_removed_ET_sd <- sd(df_trials$pre__removed[df_trials$cond == 'ET'])
pre_trials_all_removed_TS_sd <- sd(df_trials$pre__removed[df_trials$cond == 'TS'])
pre_trials_all_removed_ET_IQR <- IQR(df_trials$pre__removed[df_trials$cond == 'ET'])
pre_trials_all_removed_TS_IQR <- IQR(df_trials$pre__removed[df_trials$cond == 'TS'])
df_trials$pre_total <- df_trials$pre_preprocessing + df_trials$pre_ica + df_trials$pre_remaining
df_trials$pre_removed <- df_trials$pre_preprocessing + df_trials$pre_ica
df_trials$pre_preprocessing
df_trials$pre_total <- df_trials$pre_processing + df_trials$pre_ica + df_trials$pre_remaining
df_trials$pre_removed <- df_trials$pre_preprocessing + df_trials$pre_ica
df_trials$pre_removed <- df_trials$pre_processing + df_trials$pre_ica
pre_trials_all_removed_ET_mean <- mean(df_trials$pre_removed[df_trials$cond == 'ET'])
pre_trials_all_removed_TS_mean <- mean(df_trials$pre_removed[df_trials$cond == 'TS'])
pre_trials_all_removed_ET_median <- median(df_trials$pre_removed[df_trials$cond == 'ET'])
pre_trials_all_removed_TS_median <- median(df_trials$pre_removed[df_trials$cond == 'TS'])
pre_trials_all_removed_ET_sd <- sd(df_trials$pre__removed[df_trials$cond == 'ET'])
pre_trials_all_removed_TS_sd <- sd(df_trials$pre__removed[df_trials$cond == 'TS'])
pre_trials_all_removed_ET_IQR <- IQR(df_trials$pre__removed[df_trials$cond == 'ET'])
pre_trials_all_removed_TS_IQR <- IQR(df_trials$pre__removed[df_trials$cond == 'TS'])
mean(df_trials$pre_removed[df_trials$cond == 'ET'])
mean(df_trials$pre_removed[df_trials$cond == 'TS'])
median(df_trials$pre_removed[df_trials$cond == 'ET'])
median(df_trials$pre_removed[df_trials$cond == 'TS'])
pre_trials_all_removed_ET_sd <- sd(df_trials$pre_removed[df_trials$cond == 'ET'])
pre_trials_all_removed_TS_sd <- sd(df_trials$pre_removed[df_trials$cond == 'TS'])
pre_trials_all_removed_ET_IQR <- IQR(df_trials$pre_removed[df_trials$cond == 'ET'])
pre_trials_all_removed_TS_IQR <- IQR(df_trials$pre_removed[df_trials$cond == 'TS'])
wilcox.test(df_trials$pre_removed[df_trials$cond == 'ET'], df_trials$pre_removed[df_trials$cond == 'TS'], alternative = "two.sided")
pre_trials_remaining_ET_mean <- mean(df_trials$pre_remaining[df_trials$cond == 'ET'])
pre_trials_remaining_TS_mean <- mean(df_trials$pre_remaining[df_trials$cond == 'TS'])
